{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T15:49:50.927055Z",
     "start_time": "2026-02-18T15:49:50.922801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "########################## Proceso ETL - Huawei 3G ##########################\n",
    "# MA. 20250923.\n",
    "\n",
    "# Librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.styles import Alignment\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "\n",
    "## Variables compartidas\n",
    "\n",
    "# Ubicación archivos\n",
    "ruta_carpeta = \"C:/Users/SCaracoza/Documents/AT&T/LST Cell Ran/Huawei/Huawei-Feb\"\n",
    "\n",
    "ruta_ept = \"C:/Users/SCaracoza/Documents/AT&T/LST Cell Ran/Huawei/Huawei-Feb\"\n",
    "\n",
    "ruta_destino = \"C:/Users/SCaracoza/Documents/AT&T/LST Cell Ran/Huawei/Huawei-Feb\"\n",
    "\n",
    "# Fecha para el nombre de los archivos a crear\n",
    "fecha_ejecucion: str = datetime.now().strftime(\"%Y%m\")"
   ],
   "id": "9764f221f9d3d314",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T15:50:07.902078Z",
     "start_time": "2026-02-18T15:49:57.167316Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MA. 20250926\n",
    "### LST UCELL. Lectura y unificación de archivos. ###\n",
    "\n",
    "# Prefijo de archivos\n",
    "archivo_prefijo = \"MML_Task_Result_LST UCELL_c\"\n",
    "archivos_txt = glob.glob(os.path.join(ruta_carpeta, f\"{archivo_prefijo}*.txt\"))\n",
    "\n",
    "# Regex\n",
    "pat_section = re.compile(r\"(MML Command-----LST UCELL.*?)(?=MML Command-----LST UCELL|$)\", re.S)\n",
    "pat_ne = re.compile(r\"NE\\s*:\\s*(\\S+)\")\n",
    "pat_plus = re.compile(r\"^\\+\\+\\+\\s+(\\S+)\", re.M)\n",
    "\n",
    "# Columnas estándar\n",
    "columnas_lst = [\n",
    "    \"Origen\", \"RNC\", \"Logical RNC ID\", \"Cell ID\", \"Cell Name\", \"Max Transmit Power of Cell\",\n",
    "    \"Band Indicator\", \"Cn Operator Group Index\", \"UL Frequency Ind\", \"Uplink UARFCN\",\n",
    "    \"Downlink UARFCN\", \"Time Offset\", \"Num of Continuous in Sync Ind\",\n",
    "    \"Num of Continuous Out of Sync Ind\", \"Radio Link Failure Timer Length\",\n",
    "    \"DL Power Control Mode 1\", \"DL Primary Scrambling Code\", \"TX Diversity Indication\",\n",
    "    \"Service Priority Group Identity\", \"NodeB Name\", \"Local Cell ID\",\n",
    "    \"Location Area Code\", \"Service Area Code\", \"RAC Configuration Indication\",\n",
    "    \"Routing Area Code\", \"STTD Support Indicator\", \"CP1 Support Indicator\",\n",
    "    \"Closed Loop Time Adjust Mode\", \"DPCH Tx Diversity Mode for Other User\",\n",
    "    \"FDPCH Tx Diversity Mode for Other User\", \"DPCH Tx Diversity Mode for MIMO User\",\n",
    "    \"FDPCH Tx Diversity Mode for MIMO User\", \"Tx Diversity Mode for DC-HSDPA User\",\n",
    "    \"Cell Oriented Cell Individual Offset\", \"Cell VP Limit Indicator\", \"DSS Cell Flag\",\n",
    "    \"Maximum TX Power in Small DSS Coverage\", \"Common Channel Bandwidth Operator Index\",\n",
    "    \"Hierarchy ID of Terminal Type\", \"Heterogeneous Cell Flag\", \"HostType\",\n",
    "    \"Validation indication\", \"Cell administrative state\", \"Cell MIMO state\",\n",
    "    \"IPDL flag\", \"Cell CBS state\", \"Cell ERACH state\",\n",
    "    \"Subrack No.\", \"Subrack name\", \"Slot No.\", \"Subsystem No.\", \"Cell MBMS state\",\n",
    "    \"SSN\"\n",
    "]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for archivo in archivos_txt:\n",
    "    with open(archivo, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        contenido = f.read()\n",
    "\n",
    "    # Divide por secciones de MML Command\n",
    "    secciones = pat_section.findall(contenido)\n",
    "\n",
    "    for seccion in secciones:\n",
    "        # Detecta NE\n",
    "        m_ne = pat_ne.search(seccion)\n",
    "        ne_actual = m_ne.group(1) if m_ne else \"\"\n",
    "\n",
    "        # Si NE no existe, intenta con +++\n",
    "        if not ne_actual:\n",
    "            m_plus = pat_plus.search(seccion)\n",
    "            if m_plus:\n",
    "                ne_actual = m_plus.group(1)\n",
    "\n",
    "        # Divide en bloques de List Cell Basic Information\n",
    "        bloques = re.split(r\"List Cell Basic Information\\s*-+\\s*\", seccion)[1:]\n",
    "\n",
    "        for bloque in bloques:\n",
    "            lineas = bloque.strip().splitlines()\n",
    "            if len(lineas) < 2:\n",
    "                continue\n",
    "\n",
    "            encabezado = re.split(r\"\\s{2,}\", lineas[0].strip())\n",
    "            datos = []\n",
    "\n",
    "            for linea in lineas[1:]:\n",
    "                if linea.strip().startswith((\"---\", \"+++\", \"Number of results\", \"To be continued\")):\n",
    "                    break\n",
    "                if not linea.strip():\n",
    "                    continue\n",
    "                fila = re.split(r\"\\s{2,}\", linea.strip())\n",
    "                if len(fila) < len(encabezado):\n",
    "                    fila += [\"\"] * (len(encabezado) - len(fila))\n",
    "                elif len(fila) > len(encabezado):\n",
    "                    fila = fila[:len(encabezado)]\n",
    "                datos.append(fila)\n",
    "\n",
    "            if datos:\n",
    "                df_tmp = pd.DataFrame(datos, columns=encabezado)\n",
    "                df_tmp[\"Origen\"] = os.path.basename(archivo)\n",
    "                df_tmp[\"RNC\"] = ne_actual\n",
    "\n",
    "                # Normaliza columnas\n",
    "                for col in columnas_lst:\n",
    "                    if col not in df_tmp.columns:\n",
    "                        df_tmp[col] = \"\"\n",
    "\n",
    "                df_tmp = df_tmp[columnas_lst]\n",
    "                dfs.append(df_tmp)\n",
    "\n",
    "# Unión\n",
    "df_final = pd.concat(dfs, ignore_index=True, sort=False) if dfs else pd.DataFrame(columns=columnas_lst)\n",
    "\n",
    "# --- Limpieza y transformaciones ---\n",
    "df_final.columns = df_final.columns.str.strip().str.replace(r\"\\s+\", \" \", regex=True)\n",
    "df_final = df_final.loc[:, ~df_final.columns.duplicated()]\n",
    "\n",
    "# Reemplaza <NULL> en Uplink UARFCN\n",
    "if \"Uplink UARFCN\" in df_final.columns:\n",
    "    df_final[\"Uplink UARFCN\"] = df_final[\"Uplink UARFCN\"].replace(\"<NULL>\", \"0\")\n",
    "\n",
    "# Asegura columnas de SSN\n",
    "for col in [\"Subrack No.\", \"Slot No.\", \"Subsystem No.\"]:\n",
    "    if col not in df_final.columns:\n",
    "        df_final[col] = \"\"\n",
    "\n",
    "# Genera SSN\n",
    "df_final[\"SSN\"] = (\n",
    "    df_final[[\"Subrack No.\", \"Slot No.\", \"Subsystem No.\"]]\n",
    "    .astype(str).fillna(\"\")\n",
    "    .agg(\"-\".join, axis=1)\n",
    ")\n",
    "df_final[\"SSN\"] = df_final[\"SSN\"].apply(lambda x: \"--\" if x.replace(\"-\", \"\").strip() == \"\" else x)\n",
    "\n",
    "# Filtrado\n",
    "if \"Logical RNC ID\" in df_final.columns:\n",
    "    df_final = df_final[~df_final[\"Logical RNC ID\"].str.contains(r\"\\+\\+\\+\", na=False)]\n",
    "if \"Cell Name\" in df_final.columns:\n",
    "    df_final = df_final[df_final[\"Cell Name\"].astype(str).str.strip() != \"\"]\n",
    "\n",
    "# Convierte columnas numéricas cuando aplica\n",
    "df_LST_UCELL_inicial = df_final.apply(\n",
    "    lambda col: pd.to_numeric(col, errors=\"coerce\")\n",
    "    if not pd.to_numeric(col, errors=\"coerce\").isna().any()\n",
    "    else col\n",
    ")\n",
    "\n",
    "# Archivo unificado en Excel (validación)\n",
    "#salida_excel = os.path.join(ruta_destino, f\"LST_UCELL_{fecha_ejecucion}.xlsx\")\n",
    "#df_LST_UCELL_inicial[columnas_lst].to_excel(salida_excel, index=False, engine=\"openpyxl\")"
   ],
   "id": "8d33b6d897bc1d9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T15:50:34.019192Z",
     "start_time": "2026-02-18T15:50:31.898060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MA. 20250929\n",
    "### DSP UCELL. Lectura y unificación de archivos. ###\n",
    "\n",
    "# Prefijo de archivos\n",
    "archivo_prefijo_dsp = \"MML_Task_Result_DSP UCELL_\"\n",
    "archivos_dsp = glob.glob(os.path.join(ruta_carpeta, f\"{archivo_prefijo_dsp}*.txt\"))\n",
    "\n",
    "# Columnas esperadas\n",
    "columnas_dsp = [\n",
    "    \"Cell ID\", \"Cell Name\", \"Operation state\", \"Administrative state\",\n",
    "    \"DSS state\", \"State explanation\", \"Subrack No.\", \"Slot No.\", \"Subsystem No.\"\n",
    "]\n",
    "\n",
    "dfs_dsp = []\n",
    "\n",
    "if archivos_dsp:\n",
    "    for archivo in archivos_dsp:\n",
    "        with open(archivo, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            contenido = f.read()\n",
    "\n",
    "        # Divide en bloques a partir de \"Cell state information\"\n",
    "        bloques = re.split(r\"Cell state information\\s*-+\\s*\", contenido)[1:]\n",
    "\n",
    "        for bloque in bloques:\n",
    "            lineas = bloque.strip().splitlines()\n",
    "            if len(lineas) < 2:\n",
    "                continue\n",
    "\n",
    "            encabezado = re.split(r\"\\s{2,}\", lineas[0].strip())\n",
    "            datos = []\n",
    "\n",
    "            for linea in lineas[1:]:\n",
    "                if linea.strip().startswith((\"---\", \"+++\", \"To be continued\", \"Number of results\")):\n",
    "                    break\n",
    "                if not linea.strip():\n",
    "                    continue\n",
    "\n",
    "                fila = re.split(r\"\\s{2,}\", linea.strip())\n",
    "                # Normaliza longitud\n",
    "                if len(fila) < len(encabezado):\n",
    "                    fila += [\"\"] * (len(encabezado) - len(fila))\n",
    "                elif len(fila) > len(encabezado):\n",
    "                    fila = fila[:len(encabezado)]\n",
    "                datos.append(fila)\n",
    "\n",
    "            if datos:\n",
    "                df_tmp = pd.DataFrame(datos, columns=encabezado)\n",
    "                df_tmp[\"Origen\"] = os.path.basename(archivo)\n",
    "                dfs_dsp.append(df_tmp)\n",
    "\n",
    "if dfs_dsp:\n",
    "    df_DSP_UCELL_ini = pd.concat(dfs_dsp, ignore_index=True, sort=True)\n",
    "\n",
    "    # Renombra \"Cell name\" -> \"Cell Name\"\n",
    "    if \"Cell name\" in df_DSP_UCELL_ini.columns:\n",
    "        df_DSP_UCELL_ini.rename(columns={\"Cell name\": \"Cell Name\"}, inplace=True)\n",
    "\n",
    "    # Asegura columnas esperadas\n",
    "    for col in columnas_dsp:\n",
    "        if col not in df_DSP_UCELL_ini.columns:\n",
    "            df_DSP_UCELL_ini[col] = \"\"\n",
    "\n",
    "    # Reordena\n",
    "    df_DSP_UCELL_inicial = df_DSP_UCELL_ini[columnas_dsp + [\"Origen\"]]\n",
    "\n",
    "    # Elimina registros donde \"Cell Name\" esté vacío o NaN\n",
    "    if \"Cell Name\" in df_DSP_UCELL_inicial.columns:\n",
    "        df_DSP_UCELL_inicial = df_DSP_UCELL_inicial[df_DSP_UCELL_inicial[\"Cell Name\"].astype(str).str.strip() != \"\"]\n",
    "\n",
    "    # Convierte columnas numéricas cuando aplica\n",
    "    df_DSP_UCELL_inicial = df_DSP_UCELL_inicial.apply(\n",
    "        lambda col: pd.to_numeric(col, errors=\"coerce\")\n",
    "        if not pd.to_numeric(col, errors=\"coerce\").isna().any()\n",
    "        else col\n",
    "    )\n",
    "else:\n",
    "    df_DSP_UCELL_inicial = pd.DataFrame(columns=columnas_dsp + [\"Origen\"])\n",
    "\n",
    "\n",
    "# Archivo unificado en Excel (validación)\n",
    "#ruta_salida = os.path.join(ruta_destino, f\"DSP_UCELL_{fecha_ejecucion}.xlsx\")\n",
    "#df_DSP_UCELL_inicial.to_excel(ruta_salida, index=False, engine=\"openpyxl\")"
   ],
   "id": "f4f16530b34125b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T15:50:37.341093Z",
     "start_time": "2026-02-18T15:50:35.485185Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MA. 20250923.\n",
    "### LST UCELLURA. Lectura y unificación de archivos. ###\n",
    "\n",
    "# Prefijo de archivos\n",
    "archivo_prefijo_ura = \"MML_Task_Result_LST UCELLURA_c\"\n",
    "archivos_ura = glob.glob(os.path.join(ruta_carpeta, f\"{archivo_prefijo_ura}*.txt\"))\n",
    "\n",
    "# Columnas esperadas\n",
    "columnas_ura = [\"Origen\", \"NE\", \"Logical RNC ID\", \"Cell ID\", \"Cell Name\", \"URA ID\"]\n",
    "\n",
    "dfs_ura = []\n",
    "\n",
    "if archivos_ura:\n",
    "    for archivo in archivos_ura:\n",
    "        with open(archivo, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            contenido = f.read()\n",
    "\n",
    "        # Detecta NE (si viene vacío, lo toma de +++)\n",
    "        ne_actual = None\n",
    "        m_ne = re.search(r\"^NE\\s*:\\s*(\\S+)?\", contenido, re.MULTILINE)\n",
    "        if m_ne and m_ne.group(1):\n",
    "            ne_actual = m_ne.group(1)\n",
    "        else:\n",
    "            m_plus = re.search(r\"^\\+\\+\\+\\s+(\\S+)\", contenido, re.MULTILINE)\n",
    "            if m_plus:\n",
    "                ne_actual = m_plus.group(1)\n",
    "\n",
    "        # Divide por bloques de tabla \"List Cell URA\"\n",
    "        bloques = re.split(r\"List Cell URA\\s*-+\\s*\", contenido)[1:]\n",
    "\n",
    "        for bloque in bloques:\n",
    "            lineas = bloque.strip().splitlines()\n",
    "            if len(lineas) < 2:\n",
    "                continue\n",
    "\n",
    "            # Encabezado y datos\n",
    "            encabezado = re.split(r\"\\s{2,}\", lineas[0].strip())\n",
    "            datos = []\n",
    "            for linea in lineas[1:]:\n",
    "                if linea.strip().startswith((\"---\", \"+++\", \"Number of results\", \"To be continued\")):\n",
    "                    break\n",
    "                if not linea.strip():\n",
    "                    continue\n",
    "                fila = re.split(r\"\\s{2,}\", linea.strip())\n",
    "                if len(fila) < len(encabezado):\n",
    "                    fila += [\"\"] * (len(encabezado) - len(fila))\n",
    "                elif len(fila) > len(encabezado):\n",
    "                    fila = fila[:len(encabezado)]\n",
    "                datos.append(fila)\n",
    "\n",
    "            if datos:\n",
    "                df_tmp = pd.DataFrame(datos, columns=encabezado)\n",
    "                df_tmp[\"Origen\"] = os.path.basename(archivo)\n",
    "                df_tmp[\"NE\"] = ne_actual\n",
    "                dfs_ura.append(df_tmp)\n",
    "\n",
    "# Une resultados\n",
    "if dfs_ura:\n",
    "    df_LST_UCELLURA_ini = pd.concat(dfs_ura, ignore_index=True, sort=True)\n",
    "\n",
    "    # Reordena y garantiza columnas esperadas\n",
    "    for col in columnas_ura:\n",
    "        if col not in df_LST_UCELLURA_ini.columns:\n",
    "            df_LST_UCELLURA_ini[col] = \"\"\n",
    "\n",
    "    df_LST_UCELLURA_inicial = df_LST_UCELLURA_ini[columnas_ura]\n",
    "\n",
    "\n",
    "# Elimina registros donde \"Cell Name\" esté vacío o NaN\n",
    "    if \"Cell Name\" in df_LST_UCELLURA_inicial.columns:\n",
    "        df_LST_UCELLURA_inicial = df_LST_UCELLURA_inicial[\n",
    "        df_LST_UCELLURA_inicial[\"Cell Name\"].astype(str).str.strip() != \"\"\n",
    "    ]\n",
    "else:\n",
    "    df_LST_UCELLURA_inicial = pd.DataFrame(columns=columnas_ura)\n",
    "\n",
    "# Convierte columnas numéricas si aplica\n",
    "df_LST_UCELLURA_inicial = df_LST_UCELLURA_inicial.apply(\n",
    "    lambda col: pd.to_numeric(col, errors=\"coerce\")\n",
    "    if not pd.to_numeric(col, errors=\"coerce\").isna().any()\n",
    "    else col\n",
    ")\n",
    "\n",
    "# Archivo unificado en CSV, para fines de validación.\n",
    "#ruta_salida = os.path.join(ruta_destino, f\"LST_UCELLURA_{fecha_ejecucion}.xlsx\")\n",
    "#df_LST_UCELLURA_inicial.to_excel(ruta_salida, index=False, engine=\"openpyxl\")"
   ],
   "id": "4bb8a680e5736a4e",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T15:52:46.928704Z",
     "start_time": "2026-02-18T15:50:39.307431Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MA. 20250924.\n",
    "### Información archivo mes anterior ###\n",
    "\n",
    "# Sufijo mes anterior\n",
    "today = date.today()\n",
    "prev_year  = today.year if today.month > 1 else today.year - 1\n",
    "prev_month = today.month - 1 or 12\n",
    "yyyymm = f\"{prev_year}{prev_month:02d}\"\n",
    "fecha_hoy = today.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "# Busca archivo\n",
    "ruta: str = ruta_destino  # --> MA. Por Definir.\n",
    "archivo = f\"All_Huawei_3G_{yyyymm}.xlsx\"\n",
    "path = os.path.join(ruta, archivo)\n",
    "\n",
    "# Columnas necesarias\n",
    "columnas_anteriores = [\"ANT Cell Id\", \"ANT Cell Name\", \"RNC\", \"LAT\", \"LON\", \"AT&T_Site_Name\", \"En el gestor\"]\n",
    "\n",
    "if os.path.exists(path):\n",
    "    # Fecha del día y de creación de archivo anterior\n",
    "    wb = load_workbook(path, read_only=True)\n",
    "    props = wb.properties\n",
    "    fecha_creacion = props.created.strftime(\"%d/%m/%Y\")\n",
    "\n",
    "    # Extrae columnas necesarias\n",
    "    df_All_Huawei_3G_Anterior = pd.read_excel(\n",
    "        path,\n",
    "        usecols=[\"Cell Id\", \"Cell Name\", \"LAT\", \"LON\", \"AT&T_Site_Name\", \"En el gestor\"]\n",
    "    )\n",
    "\n",
    "    # Renombra columnas llave\n",
    "    df_All_Huawei_3G_Anterior = df_All_Huawei_3G_Anterior.rename(\n",
    "        columns={\"Cell Id\": \"ANT Cell Id\", \"Cell Name\": \"ANT Cell Name\"}\n",
    "    )\n",
    "\n",
    "    ## Formato columna \"En el gestor\"\n",
    "    df_All_Huawei_3G_Anterior[\"En el gestor\"] = df_All_Huawei_3G_Anterior[\"En el gestor\"].apply(\n",
    "    lambda x: pd.to_datetime(x, dayfirst=True, errors=\"coerce\")\n",
    "              .strftime(\"%d/%m/%Y\") if not pd.isna(pd.to_datetime(x, dayfirst=True, errors=\"coerce\")) else x\n",
    "        )\n",
    "\n",
    "else:\n",
    "    # No existe archivo, crea DataFrame vacío con columnas necesarias\n",
    "    df_All_Huawei_3G_Anterior = pd.DataFrame(columns=columnas_anteriores)"
   ],
   "id": "2ffaa94401f0c280",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T15:55:51.983428Z",
     "start_time": "2026-02-18T15:52:46.947890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MA. 20250926.\n",
    "### Información del EPT ###\n",
    "\n",
    "# Prefijo del archivo\n",
    "prefijo_ept = \"EPT_ATT_UMTS_LTE_\"\n",
    "\n",
    "# Busca archivo que empiece con el prefijo\n",
    "archivo = glob.glob(os.path.join(ruta_ept, f\"{prefijo_ept}*.xlsx\"))\n",
    "\n",
    "# Inicializa por si no hay archivo\n",
    "df_EPT_ini = pd.DataFrame()\n",
    "df_EPT_unificado = pd.DataFrame(columns=[\"Cell Name\", \"LAT\", \"LON\", \"AT&T_Site_Name\"])\n",
    "df_EPT_nodes = pd.DataFrame(columns=[\"node_key\", \"LAT\", \"LON\", \"AT&T_Site_Name\"])\n",
    "\n",
    "if archivo:\n",
    "    archivo_encontrado = archivo[0]\n",
    "    nombre_archivo = os.path.basename(archivo_encontrado)\n",
    "\n",
    "    # Lista de hojas a leer\n",
    "    hojas = [\n",
    "        \"EPT_3G_LTE_OUTDOOR\",\n",
    "        \"PLAN_OUTDOOR\",\n",
    "        \"EPT_3G_LTE_INDOOR\",\n",
    "        \"PLAN_INDOOR\",\n",
    "        \"Eventos_Especiales\"\n",
    "    ]\n",
    "\n",
    "    # Lee todas las hojas y agrega el nombre de la hoja en columna\n",
    "    dfs = [\n",
    "        pd.read_excel(archivo_encontrado, sheet_name=hoja, engine=\"openpyxl\")\n",
    "        .assign(Hoja=hoja, Origen=nombre_archivo)\n",
    "        for hoja in hojas\n",
    "    ]\n",
    "\n",
    "    # Concatena todo en un solo DataFrame\n",
    "    df_EPT_inicial = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    # Elimina duplicados\n",
    "    df_EPT_inicial = df_EPT_inicial.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # Renombramiento columna(s)\n",
    "    nuevos_nombres = {\"CellName\": \"Cell Name\", \"Latitud\": \"LAT\", \"Longitud\": \"LON\"}\n",
    "    df_EPT_inicial.rename(columns=nuevos_nombres, inplace=True)\n",
    "\n",
    "    # Convierte columnas totalmente numéricas (cuando aplica)\n",
    "    df_EPT_ini = df_EPT_inicial.apply(\n",
    "        lambda col: pd.to_numeric(col, errors=\"coerce\")\n",
    "        if not pd.to_numeric(col, errors=\"coerce\").isna().any()\n",
    "        else col\n",
    "    )\n",
    "\n",
    "    # -------------------------------\n",
    "    # 1) EPT por Cell Name (como ya tenías)\n",
    "    # -------------------------------\n",
    "    df_EPT_unificado = df_EPT_ini[[\"Cell Name\", \"LAT\", \"LON\", \"AT&T_Site_Name\"]]\n",
    "\n",
    "    # -------------------------------\n",
    "    # 2) EPT por NodeB Name (preparado aquí)\n",
    "    #    Genera una tabla \"larga\" con AT&T_Node_Name y Node_B_U2000\n",
    "    # -------------------------------\n",
    "    cols_nodo_ept = [c for c in [\"AT&T_Node_Name\", \"Node_B_U2000\"] if c in df_EPT_ini.columns]\n",
    "    cols_site = [c for c in [\"LAT\", \"LON\", \"AT&T_Site_Name\"] if c in df_EPT_ini.columns]\n",
    "\n",
    "    if cols_nodo_ept and set([\"LAT\", \"LON\", \"AT&T_Site_Name\"]).issubset(df_EPT_ini.columns):\n",
    "\n",
    "        df_ept_nodes_raw = (\n",
    "            df_EPT_ini[cols_site + cols_nodo_ept]\n",
    "            .melt(id_vars=cols_site, value_vars=cols_nodo_ept, value_name=\"node_name\")\n",
    "            .drop(columns=[\"variable\"])\n",
    "            .dropna(subset=[\"node_name\"])\n",
    "            .drop_duplicates()\n",
    "            .reset_index(drop=True)\n",
    "        )\n",
    "\n",
    "        # Normalizador consistente\n",
    "        def _norm(s: str) -> str:\n",
    "            s = str(s)\n",
    "            return (s.upper()\n",
    "                      .replace(\" \", \"\")\n",
    "                      .replace(\"_\", \"\")\n",
    "                      .replace(\"-\", \"\")\n",
    "                      .replace(\".\", \"\")\n",
    "                      .strip())\n",
    "\n",
    "        df_ept_nodes_raw[\"node_key\"] = df_ept_nodes_raw[\"node_name\"].map(_norm)\n",
    "\n",
    "        # Mantén una fila por node_key (si hay duplicados, toma la primera con datos)\n",
    "        df_EPT_nodes = (\n",
    "            df_ept_nodes_raw\n",
    "            .drop_duplicates(subset=[\"node_key\"], keep=\"first\")\n",
    "            .loc[:, [\"node_key\", \"LAT\", \"LON\", \"AT&T_Site_Name\"]]\n",
    "            .reset_index(drop=True)\n",
    "        )\n"
   ],
   "id": "e3732eb14de95941",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-18T16:46:58.406266Z",
     "start_time": "2026-02-18T16:33:41.176732Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MA. 20250923.\n",
    "### Creación archivo final ###\n",
    "\n",
    "## Extraemos solo las columnas requeridas de cada DataFrame.\n",
    "\n",
    "## LST_UCELL\n",
    "df_LST_UCELL = df_LST_UCELL_inicial[[\n",
    "    \"RNC\",\"Logical RNC ID\",\"Cell ID\",\"Cell Name\",\"Max Transmit Power of Cell\",\"Band Indicator\",\n",
    "    \"Cn Operator Group Index\",\"UL Frequency Ind\",\"Uplink UARFCN\",\"Downlink UARFCN\",\"Time Offset\",\n",
    "    \"Num of Continuous in Sync Ind\",\"Num of Continuous Out of Sync Ind\",\"Radio Link Failure Timer Length\",\n",
    "    \"DL Power Control Mode 1\",\"DL Primary Scrambling Code\",\"TX Diversity Indication\",\n",
    "    \"Service Priority Group Identity\",\"NodeB Name\",\"Local Cell ID\",\"Location Area Code\",\"Service Area Code\",\n",
    "    \"RAC Configuration Indication\",\"Routing Area Code\",\"STTD Support Indicator\",\"CP1 Support Indicator\",\n",
    "    \"Closed Loop Time Adjust Mode\",\"DPCH Tx Diversity Mode for Other User\",\"FDPCH Tx Diversity Mode for Other User\",\n",
    "    \"DPCH Tx Diversity Mode for MIMO User\",\"FDPCH Tx Diversity Mode for MIMO User\",\"Tx Diversity Mode for DC-HSDPA User\",\n",
    "    \"Cell Oriented Cell Individual Offset\",\"Cell VP Limit Indicator\",\"DSS Cell Flag\",\n",
    "    \"Maximum TX Power in Small DSS Coverage\",\"Common Channel Bandwidth Operator Index\",\n",
    "    \"Hierarchy ID of Terminal Type\",\"Heterogeneous Cell Flag\",\"HostType\",\"Validation indication\",\n",
    "    \"Cell administrative state\",\"Cell MIMO state\",\"IPDL flag\",\"Cell CBS state\",\"Cell ERACH state\",\n",
    "    \"Subrack No.\",\"Subrack name\",\"Slot No.\",\"Subsystem No.\",\"Cell MBMS state\",\"SSN\"\n",
    "]]\n",
    "df_LST_UCELL = df_LST_UCELL.rename(columns={\"Logical RNC ID\": \"RNC ID\"})\n",
    "# >>> NUEVO: columna Gestor a partir de 'Origen' del LST <<<\n",
    "# 'Origen' existe en df_LST_UCELL_inicial porque lo agregaste al leer cada archivo.\n",
    "_gestor = df_LST_UCELL_inicial[\"Origen\"].str.extract(r\"LST UCELL_c(\\d+)\", expand=True).iloc[:, 0]\n",
    "df_LST_UCELL[\"Gestor\"] = np.where(_gestor.notna() & (_gestor != \"\"), \"MAE-\" + _gestor.astype(str), \"\")\n",
    "\n",
    "\n",
    "## DSP_UCELL\n",
    "df_DSP_UCELL = df_DSP_UCELL_inicial[[\n",
    "    \"Cell ID\",\"Cell Name\",\"Operation state\",\"Administrative state\",\"State explanation\"\n",
    "]]\n",
    "\n",
    "## LST_UCELLURA\n",
    "df_LST_UCELLURA = df_LST_UCELLURA_inicial[[\"Cell ID\",\"Cell Name\",\"URA ID\"]]\n",
    "df_LST_UCELLURA = df_LST_UCELLURA.rename(columns={\"URA ID\": \"URA\"})\n",
    "\n",
    "## Joins base\n",
    "df_Huawei_3G_inicial = df_LST_UCELL.merge(df_DSP_UCELL, on=[\"Cell ID\",\"Cell Name\"], how=\"left\")\n",
    "df_Huawei_3G_inicial = df_Huawei_3G_inicial.merge(df_LST_UCELLURA, on=[\"Cell ID\",\"Cell Name\"], how=\"left\")\n",
    "\n",
    "## Archivo anterior\n",
    "df_Huawei_3G_inicial = pd.merge(\n",
    "    df_Huawei_3G_inicial, df_All_Huawei_3G_Anterior,\n",
    "    left_on=[\"Cell ID\",\"Cell Name\"], right_on=[\"ANT Cell Id\",\"ANT Cell Name\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "## EPT por Cell Name\n",
    "df_Huawei_3G_inicial = df_Huawei_3G_inicial.merge(\n",
    "    df_EPT_unificado, on=\"Cell Name\", suffixes=(\"\", \"_EPT\"), how=\"left\"\n",
    ")\n",
    "\n",
    "# Fallback por Cell Name\n",
    "fallback_map = {\n",
    "    \"LAT\": \"LAT_EPT\",\n",
    "    \"LON\": \"LON_EPT\",\n",
    "    \"AT&T_Site_Name\": \"AT&T_Site_Name_EPT\"\n",
    "}\n",
    "\n",
    "for col, col_ept in fallback_map.items():\n",
    "    if col in df_Huawei_3G_inicial.columns and col_ept in df_Huawei_3G_inicial.columns:\n",
    "        # EPT = fuente primaria, AE (col) = respaldo\n",
    "        ept_vals = df_Huawei_3G_inicial[col_ept].replace(\"\", np.nan)\n",
    "        ae_vals  = df_Huawei_3G_inicial[col].replace(\"\", np.nan)\n",
    "        df_Huawei_3G_inicial[col] = ept_vals.combine_first(ae_vals)\n",
    "\n",
    "# (Opcional) Limpia columnas *_EPT\n",
    "df_Huawei_3G_inicial.drop(columns=[\"LAT_EPT\",\"LON_EPT\",\"AT&T_Site_Name_EPT\"],\n",
    "                          inplace=True, errors=\"ignore\")\n",
    "\n",
    "## Fallback adicional por NodeB Name usando df_EPT_nodes (preparado en el bloque EPT)\n",
    "if 'df_EPT_nodes' in globals() and not df_EPT_nodes.empty:\n",
    "    def _norm(s: str) -> str:\n",
    "        s = str(s)\n",
    "        return (s.upper().replace(\" \",\"\").replace(\"_\",\"\").replace(\"-\",\"\").replace(\".\",\"\").strip())\n",
    "\n",
    "    # Solo filas que aún falten LAT/LON/Site\n",
    "    mask_missing = (\n",
    "        df_Huawei_3G_inicial[[\"LAT\",\"LON\",\"AT&T_Site_Name\"]]\n",
    "        .replace(\"\", np.nan).isna().any(axis=1)\n",
    "    )\n",
    "    if mask_missing.any():\n",
    "        df_Huawei_3G_inicial.loc[mask_missing, \"node_key\"] = (\n",
    "            df_Huawei_3G_inicial.loc[mask_missing, \"NodeB Name\"].astype(str).map(_norm)\n",
    "        )\n",
    "\n",
    "        # Trae LAT/LON/Site por node_key\n",
    "        df_tmp = df_Huawei_3G_inicial.loc[mask_missing, [\"node_key\"]].merge(\n",
    "            df_EPT_nodes.rename(columns={\n",
    "                \"LAT\":\"LAT_ept_nb\",\n",
    "                \"LON\":\"LON_ept_nb\",\n",
    "                \"AT&T_Site_Name\":\"AT&T_Site_Name_ept_nb\"\n",
    "            }),\n",
    "            on=\"node_key\", how=\"left\"\n",
    "        )\n",
    "\n",
    "        # Escribe columnas temporales en el mismo slice\n",
    "        df_Huawei_3G_inicial.loc[mask_missing, [\"LAT_ept_nb\",\"LON_ept_nb\",\"AT&T_Site_Name_ept_nb\"]] = \\\n",
    "            df_tmp[[\"LAT_ept_nb\",\"LON_ept_nb\",\"AT&T_Site_Name_ept_nb\"]].values\n",
    "\n",
    "        # Rellena solo lo que sigue vacío\n",
    "        for col, nb_col in [(\"LAT\",\"LAT_ept_nb\"), (\"LON\",\"LON_ept_nb\"), (\"AT&T_Site_Name\",\"AT&T_Site_Name_ept_nb\")]:\n",
    "            if col in df_Huawei_3G_inicial.columns and nb_col in df_Huawei_3G_inicial.columns:\n",
    "                df_Huawei_3G_inicial[col] = (\n",
    "                    df_Huawei_3G_inicial[col].replace(\"\", np.nan).fillna(df_Huawei_3G_inicial[nb_col])\n",
    "                )\n",
    "\n",
    "        # Limpieza\n",
    "        df_Huawei_3G_inicial.drop(columns=[\"node_key\",\"LAT_ept_nb\",\"LON_ept_nb\",\"AT&T_Site_Name_ept_nb\"],\n",
    "                                  inplace=True, errors=\"ignore\")\n",
    "\n",
    "## \"En el gestor\"\n",
    "df_Huawei_3G_inicial[\"En el gestor\"] = np.where(\n",
    "    df_Huawei_3G_inicial[\"En el gestor\"].isna() | (df_Huawei_3G_inicial[\"En el gestor\"] == \"\"),\n",
    "    fecha_hoy, df_Huawei_3G_inicial[\"En el gestor\"]\n",
    ")\n",
    "\n",
    "## Orden\n",
    "df_Huawei_3G_ordenado = df_Huawei_3G_inicial.sort_values(by=[\"RNC\",\"NodeB Name\",\"Local Cell ID\"])\n",
    "\n",
    "## Consolidado\n",
    "df_Huawei_3G_ordenado[\"Consolidado\"] = np.where(\n",
    "    df_Huawei_3G_ordenado[\"NodeB Name\"].str.len() == 10, \"Si\", \"No\"\n",
    ")\n",
    "\n",
    "## NodeB Unique\n",
    "_name = df_Huawei_3G_ordenado[\"NodeB Name\"].astype(str).fillna(\"\").str.strip()\n",
    "is_new = _name.ne(_name.shift())\n",
    "df_Huawei_3G_ordenado[\"NodeB Unique\"] = np.where(is_new & _name.ne(\"\"), df_Huawei_3G_ordenado[\"NodeB Name\"], \"\")\n",
    "\n",
    "## Renombres finales\n",
    "df_Huawei_3G_ordenado = df_Huawei_3G_ordenado.rename(columns={\"Cell ID\": \"Cell Id\"})\n",
    "\n",
    "## Numeric-only casts\n",
    "df_Huawei_3G_ordenado = df_Huawei_3G_ordenado.apply(\n",
    "    lambda col: pd.to_numeric(col, errors=\"coerce\")\n",
    "    if not pd.to_numeric(col, errors=\"coerce\").isna().any()\n",
    "    else col\n",
    ")\n",
    "\n",
    "## Estructura final\n",
    "df_Huawei_3G = df_Huawei_3G_ordenado[[\n",
    "    \"RNC\",\"Cell Id\",\"Cell Name\",\"RNC ID\",\"Max Transmit Power of Cell\",\"Band Indicator\",\n",
    "    \"Cn Operator Group Index\",\"UL Frequency Ind\",\"Uplink UARFCN\",\"Downlink UARFCN\",\"Time Offset\",\n",
    "    \"Num of Continuous in Sync Ind\",\"Num of Continuous Out of Sync Ind\",\"Radio Link Failure Timer Length\",\n",
    "    \"DL Power Control Mode 1\",\"DL Primary Scrambling Code\",\"TX Diversity Indication\",\n",
    "    \"Service Priority Group Identity\",\"NodeB Name\",\"Local Cell ID\",\"Location Area Code\",\"Service Area Code\",\n",
    "    \"RAC Configuration Indication\",\"Routing Area Code\",\"STTD Support Indicator\",\"CP1 Support Indicator\",\n",
    "    \"Closed Loop Time Adjust Mode\",\"DPCH Tx Diversity Mode for Other User\",\"FDPCH Tx Diversity Mode for Other User\",\n",
    "    \"DPCH Tx Diversity Mode for MIMO User\",\"FDPCH Tx Diversity Mode for MIMO User\",\"Tx Diversity Mode for DC-HSDPA User\",\n",
    "    \"Cell Oriented Cell Individual Offset\",\"Cell VP Limit Indicator\",\"DSS Cell Flag\",\n",
    "    \"Maximum TX Power in Small DSS Coverage\",\"Common Channel Bandwidth Operator Index\",\n",
    "    \"Hierarchy ID of Terminal Type\",\"Subrack No.\",\"Subrack name\",\"Slot No.\",\"Subsystem No.\",\n",
    "    \"Heterogeneous Cell Flag\",\"HostType\",\"Validation indication\",\"Cell administrative state\",\"Cell MBMS state\",\n",
    "    \"Cell MIMO state\",\"IPDL flag\",\"Cell CBS state\",\"Cell ERACH state\",\"NodeB Unique\",\"LAT\",\"LON\",\n",
    "    \"Operation state\",\"Administrative state\",\"State explanation\",\"SSN\",\"En el gestor\",\"URA\",\"Consolidado\",\n",
    "    \"AT&T_Site_Name\", \"Gestor\"\n",
    "]]\n",
    "\n",
    "## Archivo Final\n",
    "ruta_salida = os.path.join(ruta_destino, f\"All_Huawei_3G_{fecha_ejecucion}.xlsx\")\n",
    "df_Huawei_3G.to_excel(ruta_salida, index=False, engine=\"openpyxl\")\n",
    "\n",
    "# Rotar encabezados\n",
    "wb = load_workbook(ruta_salida)\n",
    "ws = wb.active\n",
    "for col_num, column_title in enumerate(df_Huawei_3G.columns, 1):\n",
    "    cell = ws[f\"{get_column_letter(col_num)}1\"]\n",
    "    cell.alignment = Alignment(textRotation=90, horizontal=\"center\", vertical=\"bottom\")\n",
    "wb.save(ruta_salida)\n"
   ],
   "id": "3fdc40bc99d18f67",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[10]\u001B[39m\u001B[32m, line 163\u001B[39m\n\u001B[32m    161\u001B[39m \u001B[38;5;66;03m## Archivo Final\u001B[39;00m\n\u001B[32m    162\u001B[39m ruta_salida = os.path.join(ruta_destino, \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mAll_Huawei_3G_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfecha_ejecucion\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.xlsx\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m163\u001B[39m \u001B[43mdf_Huawei_3G\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto_excel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mruta_salida\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mopenpyxl\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[32m    165\u001B[39m \u001B[38;5;66;03m# Rotar encabezados\u001B[39;00m\n\u001B[32m    166\u001B[39m wb = load_workbook(ruta_salida)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001B[39m, in \u001B[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    327\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) > num_allow_args:\n\u001B[32m    328\u001B[39m     warnings.warn(\n\u001B[32m    329\u001B[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001B[32m    330\u001B[39m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[32m    331\u001B[39m         stacklevel=find_stack_level(),\n\u001B[32m    332\u001B[39m     )\n\u001B[32m--> \u001B[39m\u001B[32m333\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:2436\u001B[39m, in \u001B[36mNDFrame.to_excel\u001B[39m\u001B[34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, inf_rep, freeze_panes, storage_options, engine_kwargs)\u001B[39m\n\u001B[32m   2423\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mio\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mformats\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexcel\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m ExcelFormatter\n\u001B[32m   2425\u001B[39m formatter = ExcelFormatter(\n\u001B[32m   2426\u001B[39m     df,\n\u001B[32m   2427\u001B[39m     na_rep=na_rep,\n\u001B[32m   (...)\u001B[39m\u001B[32m   2434\u001B[39m     inf_rep=inf_rep,\n\u001B[32m   2435\u001B[39m )\n\u001B[32m-> \u001B[39m\u001B[32m2436\u001B[39m \u001B[43mformatter\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m   2437\u001B[39m \u001B[43m    \u001B[49m\u001B[43mexcel_writer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2438\u001B[39m \u001B[43m    \u001B[49m\u001B[43msheet_name\u001B[49m\u001B[43m=\u001B[49m\u001B[43msheet_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2439\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstartrow\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstartrow\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2440\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstartcol\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstartcol\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2441\u001B[39m \u001B[43m    \u001B[49m\u001B[43mfreeze_panes\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfreeze_panes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2442\u001B[39m \u001B[43m    \u001B[49m\u001B[43mengine\u001B[49m\u001B[43m=\u001B[49m\u001B[43mengine\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2443\u001B[39m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m=\u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2444\u001B[39m \u001B[43m    \u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mengine_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m   2445\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\excel.py:962\u001B[39m, in \u001B[36mExcelFormatter.write\u001B[39m\u001B[34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine, storage_options, engine_kwargs)\u001B[39m\n\u001B[32m    959\u001B[39m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[32m    960\u001B[39m     \u001B[38;5;66;03m# make sure to close opened file handles\u001B[39;00m\n\u001B[32m    961\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m need_save:\n\u001B[32m--> \u001B[39m\u001B[32m962\u001B[39m         \u001B[43mwriter\u001B[49m\u001B[43m.\u001B[49m\u001B[43mclose\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1357\u001B[39m, in \u001B[36mExcelWriter.close\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1355\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mclose\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m   1356\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"synonym for save, to make it more file-like\"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m1357\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_save\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1358\u001B[39m     \u001B[38;5;28mself\u001B[39m._handles.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:110\u001B[39m, in \u001B[36mOpenpyxlWriter._save\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    106\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_save\u001B[39m(\u001B[38;5;28mself\u001B[39m) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    107\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    108\u001B[39m \u001B[33;03m    Save workbook to disk.\u001B[39;00m\n\u001B[32m    109\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m110\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbook\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_handles\u001B[49m\u001B[43m.\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    111\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[33m\"\u001B[39m\u001B[33mr+\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._mode \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m._handles.handle, mmap.mmap):\n\u001B[32m    112\u001B[39m         \u001B[38;5;66;03m# truncate file to the written content\u001B[39;00m\n\u001B[32m    113\u001B[39m         \u001B[38;5;28mself\u001B[39m._handles.handle.truncate()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\openpyxl\\workbook\\workbook.py:409\u001B[39m, in \u001B[36mWorkbook.save\u001B[39m\u001B[34m(self, filename)\u001B[39m\n\u001B[32m    407\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.write_only \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.worksheets:\n\u001B[32m    408\u001B[39m     \u001B[38;5;28mself\u001B[39m.create_sheet()\n\u001B[32m--> \u001B[39m\u001B[32m409\u001B[39m \u001B[43msave_workbook\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:376\u001B[39m, in \u001B[36msave_workbook\u001B[39m\u001B[34m(workbook, filename)\u001B[39m\n\u001B[32m    374\u001B[39m archive = ZipFile(filename, \u001B[33m'\u001B[39m\u001B[33mw\u001B[39m\u001B[33m'\u001B[39m, ZIP_DEFLATED, allowZip64=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m    375\u001B[39m writer = ExcelWriter(workbook, archive)\n\u001B[32m--> \u001B[39m\u001B[32m376\u001B[39m \u001B[43mwriter\u001B[49m\u001B[43m.\u001B[49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    377\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:356\u001B[39m, in \u001B[36mExcelWriter.save\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    354\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34msave\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    355\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Write data into the archive.\"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m356\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mwrite_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    357\u001B[39m     \u001B[38;5;28mself\u001B[39m.archive.close()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:85\u001B[39m, in \u001B[36mExcelWriter.write_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     82\u001B[39m     \u001B[38;5;66;03m# custom_override = Override(PartName=\"/docProps/custom.xml\", ContentType=\"application/vnd.openxmlformats-officedocument.custom-properties+xml\")\u001B[39;00m\n\u001B[32m     83\u001B[39m     \u001B[38;5;28mself\u001B[39m.manifest.append(custom_override)\n\u001B[32m---> \u001B[39m\u001B[32m85\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mwrite_worksheets\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     86\u001B[39m \u001B[38;5;28mself\u001B[39m.write_chartsheets()\n\u001B[32m     87\u001B[39m \u001B[38;5;66;03m#self.write_images()\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:318\u001B[39m, in \u001B[36mExcelWriter.write_worksheets\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    316\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m idx, ws \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(\u001B[38;5;28mself\u001B[39m.workbook.worksheets, \u001B[32m1\u001B[39m):\n\u001B[32m    317\u001B[39m     ws._id = idx\n\u001B[32m--> \u001B[39m\u001B[32m318\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mwrite_worksheet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mws\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    320\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m ws._pivots:\n\u001B[32m    321\u001B[39m         \u001B[38;5;28;01mif\u001B[39;00m p.cache \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pivot_caches:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\openpyxl\\writer\\excel.py:253\u001B[39m, in \u001B[36mExcelWriter.write_worksheet\u001B[39m\u001B[34m(self, ws)\u001B[39m\n\u001B[32m    251\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    252\u001B[39m     writer = WorksheetWriter(ws)\n\u001B[32m--> \u001B[39m\u001B[32m253\u001B[39m     \u001B[43mwriter\u001B[49m\u001B[43m.\u001B[49m\u001B[43mwrite\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    255\u001B[39m ws._rels = writer._rels\n\u001B[32m    257\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ws._comments:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_writer.py:395\u001B[39m, in \u001B[36mWorksheetWriter.write\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    391\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mwrite\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    392\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    393\u001B[39m \u001B[33;03m    High level\u001B[39;00m\n\u001B[32m    394\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m395\u001B[39m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mwrite_top\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    396\u001B[39m     \u001B[38;5;28mself\u001B[39m.write_rows()\n\u001B[32m    397\u001B[39m     \u001B[38;5;28mself\u001B[39m.write_tail()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_writer.py:103\u001B[39m, in \u001B[36mWorksheetWriter.write_top\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     94\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m     95\u001B[39m \u001B[33;03mWrite all elements up to rows:\u001B[39;00m\n\u001B[32m     96\u001B[39m \u001B[33;03mproperties\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    100\u001B[39m \u001B[33;03mcols\u001B[39;00m\n\u001B[32m    101\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    102\u001B[39m \u001B[38;5;28mself\u001B[39m.write_properties()\n\u001B[32m--> \u001B[39m\u001B[32m103\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mwrite_dimensions\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    104\u001B[39m \u001B[38;5;28mself\u001B[39m.write_views()\n\u001B[32m    105\u001B[39m \u001B[38;5;28mself\u001B[39m.write_format()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\_writer.py:73\u001B[39m, in \u001B[36mWorksheetWriter.write_dimensions\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     71\u001B[39m ref = \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m.ws, \u001B[33m'\u001B[39m\u001B[33mcalculate_dimension\u001B[39m\u001B[33m'\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m     72\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m ref:\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m     dim = SheetDimension(\u001B[43mref\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[32m     74\u001B[39m     \u001B[38;5;28mself\u001B[39m.xf.send(dim.to_tree())\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\LSTCELLRAN\\.venv\\Lib\\site-packages\\openpyxl\\worksheet\\worksheet.py:388\u001B[39m, in \u001B[36mWorksheet.calculate_dimension\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    386\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m row, col \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._cells:\n\u001B[32m    387\u001B[39m     rows.add(row)\n\u001B[32m--> \u001B[39m\u001B[32m388\u001B[39m     \u001B[43mcols\u001B[49m\u001B[43m.\u001B[49m\u001B[43madd\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcol\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    389\u001B[39m max_row = \u001B[38;5;28mmax\u001B[39m(rows)\n\u001B[32m    390\u001B[39m max_col = \u001B[38;5;28mmax\u001B[39m(cols)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-02T19:29:41.828840Z",
     "start_time": "2025-10-02T19:29:41.826022Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "7ab6149a203c8ba9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

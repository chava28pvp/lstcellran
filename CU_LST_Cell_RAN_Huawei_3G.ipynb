{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T14:20:51.536083Z",
     "start_time": "2025-09-25T14:20:51.523758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "########################## Proceso ETL - Huawei 3G ##########################\n",
    "# MA. 20250923.\n",
    "\n",
    "# Librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "\n",
    "\n",
    "## Variables compartidas\n",
    "\n",
    "# Ubicación archivos\n",
    "ruta_carpeta = 'C:/Users/MAlejandres/InnovaSolutions/Cardenas, Hector - Workshops/Documentación CU/LST CELL RAN/Huawei (1)/3G'\n",
    "\n",
    "ruta_ept = 'C:/Users/MAlejandres/OneDrive - ACS Solutions/Documents/Innova Solutions/Asignaciones y Proyectos/AT&T/Casos de Uso/LST Cell RAN/Huawei/3G'\n",
    "\n",
    "ruta_destino = 'C:/Users/MAlejandres/OneDrive - ACS Solutions/Documents/Innova Solutions/Asignaciones y Proyectos/AT&T/Casos de Uso/LST Cell RAN/Huawei/3G'\n",
    "\n",
    "# Fecha para el nombre de los archivos a crear\n",
    "fecha_ejecucion: str = datetime.now().strftime('%Y%m')\n"
   ],
   "id": "9764f221f9d3d314",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T14:20:52.981963Z",
     "start_time": "2025-09-25T14:20:51.563670Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MA. 20250923.\n",
    "### DSP UCELL. Lectura y unificación de archivos. ###\n",
    "\n",
    "# Prefijo de archivos\n",
    "archivo_fuente = 'MML_Task_Result_DSP UCELL_'\n",
    "\n",
    "archivos_txt = glob.glob(os.path.join(ruta_carpeta, f'{archivo_fuente}*.txt'))\n",
    "\n",
    "# Columnas\n",
    "columnas = [\n",
    "    'Cell ID', 'Cell name', 'Operation state', 'Administrative state',\n",
    "    'DSS state', 'State explanation', 'Subrack No.', 'Slot No.', 'Subsystem No.'\n",
    "]\n",
    "\n",
    "patron = re.compile(r'(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(.+)\\s+(\\d+)\\s+(\\d+)\\s+(\\d+)')\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for archivo in archivos_txt:\n",
    "    #print(f'Procesando archivo: {os.path.basename(archivo)}')\n",
    "    filas = []\n",
    "    with open(archivo, 'r', encoding='utf-8') as f:\n",
    "        for linea in f:\n",
    "            linea = linea.strip()\n",
    "            if not linea:\n",
    "                continue\n",
    "            match = patron.match(linea)\n",
    "            if match:\n",
    "                filas.append(match.groups())\n",
    "    if filas:\n",
    "        df_temp = pd.DataFrame(filas, columns=columnas)\n",
    "        dfs.append(df_temp)\n",
    "\n",
    "# Genera un solo DataFrame\n",
    "if dfs:\n",
    "    df_DSP_UCELL_inicial = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Renombramiento columna(s)\n",
    "nuevo_nombre = {'Cell name' : 'Cell Name'}\n",
    "\n",
    "df_DSP_UCELL_inicial.rename(columns=nuevo_nombre, inplace=True)\n",
    "\n",
    "# Archivo unificado en CSV, para fines de validación.\n",
    "#ruta_salida = os.path.join(ruta_carpeta, f'DSP_UCELL_{fecha_ejecucion}.csv')\n",
    "#df_DSP_UCELL_inicial.to_csv(ruta_salida, index=False, encoding='utf-8')"
   ],
   "id": "61e29d0007b80cde",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T14:20:55.317403Z",
     "start_time": "2025-09-25T14:20:53.058214Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# MA. 20250923.\n",
    "### LST UCELL. Lectura y unificación de archivos. ###\n",
    "\n",
    "# Prefijo de archivos\n",
    "archivo_fuente = 'MML_Task_Result_LST UCELL_'\n",
    "\n",
    "archivos_txt = glob.glob(os.path.join(ruta_carpeta, f'{archivo_fuente}*.txt'))\n",
    "\n",
    "# Columnas\n",
    "columnas = [\n",
    "    'Logical RNC ID', 'Cell ID', 'Cell Name', 'Max Transmit Power of Cell',\n",
    "    'Band Indicator', 'Cn Operator Group Index', 'UL Frequency Ind',\n",
    "    'Uplink UARFCN', 'Downlink UARFCN', 'Time Offset',\n",
    "    'Num of Continuous in Sync Ind', 'Num of Continuous Out of Sync Ind',\n",
    "    'Radio Link Failure Timer Length', 'DL Power Control Mode 1',\n",
    "    'DL Primary Scrambling Code', 'TX Diversity Indication',\n",
    "    'Service Priority Group Identity', 'NodeB Name', 'Local Cell ID',\n",
    "    'Location Area Code', 'Service Area Code', 'RAC Configuration Indication',\n",
    "    'Routing Area Code', 'STTD Support Indicator', 'CP1 Support Indicator',\n",
    "    'Closed Loop Time Adjust Mode', 'DPCH Tx Diversity Mode for Other User',\n",
    "    'FDPCH Tx Diversity Mode for Other User', 'DPCH Tx Diversity Mode for MIMO User',\n",
    "    'FDPCH Tx Diversity Mode for MIMO User', 'Tx Diversity Mode for DC-HSDPA User',\n",
    "    'Cell Oriented Cell Individual Offset', 'Cell VP Limit Indicator',\n",
    "    'DSS Cell Flag', 'Maximum TX Power in Small DSS Coverage',\n",
    "    'Common Channel Bandwidth Operator Index', 'Hierarchy ID of Terminal Type',\n",
    "    'Heterogeneous Cell Flag', 'Self Planning Flag', 'Remark',\n",
    "    'Split Cell Indicator', 'Cell Coverage Type',\n",
    "    'Network Layer ID For Flexible UE Group', 'Pole Site Identification',\n",
    "    'HostType', 'Validation indication', 'Cell administrative state',\n",
    "    'Cell MIMO state', 'IPDL flag', 'Cell CBS state', 'Cell ERACH state'\n",
    "]\n",
    "\n",
    "patron = re.compile(\n",
    "    r'(\\S+)\\s+(\\S+)\\s+(.*?)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(.*?)\\s+(\\S+)\\s+(.*?)\\s+(.*?)\\s+(\\S+)\\s+(.*?)\\s+(.*?)\\s+(.*?)\\s+(.*?)\\s+(.*?)\\s+(.*?)\\s+(.*?)\\s+(.*?)\\s+(.*?)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(.*?)\\s+(.*?)\\s+(.*?)\\s+(.*?)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)\\s+(\\S+)'\n",
    ")\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for archivo in archivos_txt:\n",
    "    filas = []\n",
    "    with open(archivo, 'r', encoding='utf-8') as f:\n",
    "        for linea in f:\n",
    "            linea = linea.strip()\n",
    "            # Ignorar las líneas vacías y las que no son datos\n",
    "            if not linea or '---' in linea or '===' in linea or 'Logical RNC ID' in linea or 'Report' in linea:\n",
    "                continue\n",
    "\n",
    "            # Buscar el patrón en la línea\n",
    "            match = patron.match(linea)\n",
    "            if match:\n",
    "                filas.append(match.groups())\n",
    "\n",
    "    if filas:\n",
    "        df_temp = pd.DataFrame(filas, columns=columnas)\n",
    "        dfs.append(df_temp)\n",
    "\n",
    "# Genera un solo DataFrame\n",
    "if dfs:\n",
    "    df_LST_UCELL_inicial = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Archivo unificado en CSV, para fines de validación.\n",
    "#ruta_salida = os.path.join(ruta_carpeta, f'LST_UCELL_{fecha_ejecucion}.csv')\n",
    "#df_LST_UCELL_inicial.to_csv(ruta_salida, index=False, encoding='utf-8')"
   ],
   "id": "8d33b6d897bc1d9",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T14:20:55.645004Z",
     "start_time": "2025-09-25T14:20:55.396671Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MA. 20250923.\n",
    "### LST UCELLURA. Lectura y unificación de archivos. ###\n",
    "\n",
    "# Prefijo de archivos\n",
    "archivo_fuente = 'MML_Task_Result_LST UCELLURA_'\n",
    "\n",
    "archivos_txt = glob.glob(os.path.join(ruta_carpeta, f'{archivo_fuente}*.txt'))\n",
    "\n",
    "# Columnas\n",
    "columnas = ['Logical RNC ID', 'Cell ID', 'Cell Name', 'URA ID']\n",
    "\n",
    "patron = re.compile(r'^\\s*(\\d+)\\s+(\\d+)\\s+(\\S+)\\s+(\\d+)\\s*$')\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for archivo in archivos_txt:\n",
    "    filas = []\n",
    "    with open(archivo, 'r', encoding='utf-8') as f:\n",
    "        for linea in f:\n",
    "            linea = linea.strip()\n",
    "            # Busca líneas que coincidan con el patrón de datos.\n",
    "            match = patron.match(linea)\n",
    "            if match:\n",
    "                filas.append(match.groups())\n",
    "    if filas:\n",
    "        df_temp = pd.DataFrame(filas, columns=columnas)\n",
    "        dfs.append(df_temp)\n",
    "\n",
    "# Genera un solo DataFrame\n",
    "if dfs:\n",
    "    df_LST_UCELLURA_inicial = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Archivo unificado en CSV, para fines de validación.\n",
    "#ruta_salida = os.path.join(ruta_carpeta, f'LST_UCELLURA_{fecha_ejecucion}.csv')\n",
    "#df_LST_UCELLURA_inicial.to_csv(ruta_salida, index=False, encoding='utf-8')"
   ],
   "id": "4bb8a680e5736a4e",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T14:21:59.916691Z",
     "start_time": "2025-09-25T14:20:55.662032Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MA. 20250924.\n",
    "### Información archivo mes anterior ###\n",
    "\n",
    "# Sufijo mes anterior\n",
    "today = date.today()\n",
    "prev_year  = today.year if today.month > 1 else today.year - 1\n",
    "prev_month = today.month - 1 or 12\n",
    "yyyymm = f'{prev_year}{prev_month:02d}'\n",
    "\n",
    "# Busca archivo\n",
    "ruta: str = ruta_destino #-->MA. Por Definir.\n",
    "All_Huawei_3G_Anterior = os.path.join(ruta, f'All_Huawei_3G_{yyyymm}.xlsx')\n",
    "\n",
    "# Extrae columnas necesarias\n",
    "df_All_Huawei_3G_Anterior = pd.read_excel(All_Huawei_3G_Anterior,usecols=['Cell Id', 'Cell Name', 'RNC', 'LAT', 'LON', 'AT&T_Site_Name'])"
   ],
   "id": "2ffaa94401f0c280",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T14:55:46.242412Z",
     "start_time": "2025-09-25T14:46:58.624873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MA. 20250924.\n",
    "### Información del EPT ###\n",
    "\n",
    "# Prefijo del archivo\n",
    "prefijo_ept = 'EPT_ATT_UMTS_LTE_'\n",
    "\n",
    "# Busca archivo que empiece con el prefijo\n",
    "archivo = glob.glob(os.path.join(ruta_ept, f'{prefijo_ept}*.xlsx'))\n",
    "\n",
    "# Verifica si se encontró archivo\n",
    "if archivo:\n",
    "    archivo_encontrado = archivo[0]\n",
    "    # Crea DataFrame por cada hoja de Excel\n",
    "    df_EPT_3G_LTE_OUTDOOR = pd.read_excel(archivo_encontrado, sheet_name='EPT_3G_LTE_OUTDOOR', engine='openpyxl')\n",
    "    df_PLAN_OUTDOOR = pd.read_excel(archivo_encontrado, sheet_name='PLAN_OUTDOOR', engine='openpyxl')\n",
    "    df_EPT_3G_LTE_INDOOR = pd.read_excel(archivo_encontrado, sheet_name='EPT_3G_LTE_INDOOR', engine='openpyxl')\n",
    "    df_PLAN_INDOOR = pd.read_excel(archivo_encontrado, sheet_name='PLAN_INDOOR', engine='openpyxl')\n",
    "    df_Eventos_Especiales = pd.read_excel(archivo_encontrado, sheet_name='Eventos_Especiales', engine='openpyxl')\n",
    "\n",
    "# Crea un solo DataFrame unificado\n",
    "lista_dfs = [df_EPT_3G_LTE_OUTDOOR, df_PLAN_OUTDOOR, df_EPT_3G_LTE_INDOOR, df_PLAN_INDOOR, df_Eventos_Especiales]\n",
    "df_EPT_inicial = pd.concat(lista_dfs, ignore_index=True)\n",
    "\n",
    "# Elimina registros duplicados\n",
    "df_EPT_inicial.drop_duplicates()\n",
    "\n",
    "# Renombramiento columna(s)\n",
    "nuevos_nombres = {'ATT_CELL_ID_Name' : 'Cell Name', 'Latitud' : 'LAT', 'Longitud' : 'LON'}\n",
    "df_EPT_inicial.rename(columns=nuevos_nombres, inplace=True)\n",
    "\n",
    "# EPT\n",
    "df_EPT_final = df_EPT_inicial[['RNC','Cell Name', 'LAT', 'LON', 'AT&T_Site_Name']]\n",
    "\n",
    "# Archivo unificado en Excel, para fines de validación.\n",
    "#ruta_salida = os.path.join(ruta_destino, f'EPT_{fecha_ejecucion}.xlsx')\n",
    "#df_EPT_final.to_excel(ruta_salida, index=False) #, encoding='utf-8')"
   ],
   "id": "e3732eb14de95941",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T16:25:06.733766Z",
     "start_time": "2025-09-25T16:25:06.405909Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MA. 20250924.\n",
    "### All_Huawei_3G_Anterior vs EPT ###\n",
    "\n",
    "# Renombramiento columnas EPT\n",
    "df_EPT_val = df_EPT_final.copy() #Crea una copia del EPT para validación\n",
    "df_EPT_val = df_EPT_val.rename(columns={'RNC' : 'EPT RNC', 'Cell Name' : 'EPT Cell Name', 'LAT' : 'EPT LAT', 'LON' : 'EPT LON', 'AT&T_Site_Name' : 'EPT AT&T_Site_Name'})\n",
    "\n",
    "# Se une la información por medio de left join, con el fin de tomar como valores principales lo proveniente del EPT.\n",
    "df_Val = pd.merge(df_EPT_val, df_All_Huawei_3G_Anterior, left_on='EPT Cell Name', right_on='Cell Name', how='left')\n",
    "\n",
    "# Reemplaza nulos o strings vacíos de Archivo Anterior con info del EPT\n",
    "df_Val['LAT'] = np.where(df_Val['LAT'].isna() | (df_Val['LAT'] == ''), df_Val['EPT LAT'], df_Val['LAT'])\n",
    "df_Val['LON'] = np.where(df_Val['LON'].isna() | (df_Val['LON'] == ''), df_Val['EPT LON'], df_Val['LON'])\n",
    "df_Val['RNC'] = np.where(df_Val['RNC'].isna() | (df_Val['RNC'] == ''), df_Val['EPT RNC'], df_Val['RNC'])\n",
    "df_Val['AT&T_Site_Name'] = np.where(df_Val['AT&T_Site_Name'].isna() | (df_Val['AT&T_Site_Name'] == ''), df_Val['EPT AT&T_Site_Name'], df_Val['AT&T_Site_Name'])\n",
    "\n",
    "## Genera DataFrame resultante\n",
    "df_EPT = df_EPT_final[['RNC','Cell Name', 'LAT', 'LON', 'AT&T_Site_Name']]\n",
    "#print(df_EPT.head(5))\n"
   ],
   "id": "871b70e9fbff3090",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-25T14:45:04.536042Z",
     "start_time": "2025-09-25T14:42:30.516084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# MA. 20250923.\n",
    "### Creación archivo final ###\n",
    "\n",
    "## Extraemos solo las columnas requeridas de cada DataFrame.\n",
    "\n",
    "## LST_UCELL\n",
    "df_LST_UCELL = df_LST_UCELL_inicial[['Logical RNC ID',\t'Cell ID',\t'Cell Name',\t'Max Transmit Power of Cell',\t'Band Indicator',\t'Cn Operator Group Index',\t'UL Frequency Ind',\t'Uplink UARFCN',\t'Downlink UARFCN',\t'Time Offset',\t'Num of Continuous in Sync Ind',\t'Num of Continuous Out of Sync Ind',\t'Radio Link Failure Timer Length',\t'DL Power Control Mode 1',\t'DL Primary Scrambling Code',\t'TX Diversity Indication',\t'Service Priority Group Identity',\t'NodeB Name',\t'Local Cell ID',\t'Location Area Code',\t'Service Area Code',\t'RAC Configuration Indication',\t'Routing Area Code',\t'STTD Support Indicator',\t'CP1 Support Indicator',\t'Closed Loop Time Adjust Mode',\t'DPCH Tx Diversity Mode for Other User',\t'FDPCH Tx Diversity Mode for Other User',\t'DPCH Tx Diversity Mode for MIMO User',\t'FDPCH Tx Diversity Mode for MIMO User',\t'Tx Diversity Mode for DC-HSDPA User',\t'Cell Oriented Cell Individual Offset',\t'Cell VP Limit Indicator',\t'DSS Cell Flag',\t'Maximum TX Power in Small DSS Coverage',\t'Common Channel Bandwidth Operator Index',\t'Hierarchy ID of Terminal Type',\t'Heterogeneous Cell Flag',\t'HostType',\t'Validation indication',\t'Cell administrative state',\t'Cell MIMO state',\t'IPDL flag',\t'Cell CBS state',\t'Cell ERACH state']]\n",
    "\n",
    "# Renombramiento columna(s)\n",
    "df_LST_UCELL = df_LST_UCELL.rename(columns={'Logical RNC ID': 'RNC ID'})\n",
    "\n",
    "\n",
    "## DSP_UCELL\n",
    "df_DSP_UCELL = df_DSP_UCELL_inicial[['Cell ID', 'Cell Name', 'Operation state',\t'Administrative state',\t'State explanation']]\n",
    "\n",
    "\n",
    "## LST_UCELLURA\n",
    "df_LST_UCELLURA = df_LST_UCELLURA_inicial[['Cell ID', 'Cell Name', 'URA ID']]\n",
    "\n",
    "# Renombramiento columna(s)\n",
    "df_LST_UCELLURA = df_LST_UCELLURA.rename(columns={'URA ID': 'URA'})\n",
    "\n",
    "\n",
    "## Se unen los DataFrames en uno solo por medio de left joins.\n",
    "df_Huawei_3G_inicial = df_LST_UCELL.merge(df_DSP_UCELL, on=['Cell ID', 'Cell Name'], how='left')\n",
    "df_Huawei_3G_inicial = df_Huawei_3G_inicial.merge(df_LST_UCELLURA, on=['Cell ID', 'Cell Name'], how='left')\n",
    "df_Huawei_3G_inicial = df_Huawei_3G_inicial.merge(df_EPT, on='Cell Name', how='left')\n",
    "\n",
    "\n",
    "## Se agregan las columnas faltantes (por definir su origen)\n",
    "df_Huawei_3G_inicial = df_Huawei_3G_inicial.assign(\n",
    "    MKT='',\n",
    "    **{'Subrack No.': ''},\n",
    "    **{'Subrack name': ''},\n",
    "    **{'Slot No.': ''},\n",
    "    **{'Subsystem No.': ''},\n",
    "    **{'Cell MBMS state': ''},\n",
    "    **{'NodeB Unique': ''},\n",
    "    SSN='',\n",
    "    **{'En el gestor': ''},\n",
    "    Observaciones='',\n",
    "    Consolidado=''\n",
    ")\n",
    "\n",
    "# Renombramiento columna(s)\n",
    "df_Huawei_3G_inicial = df_Huawei_3G_inicial.rename(columns={'Cell ID' : 'Cell Id'})\n",
    "\n",
    "## Ordenamiento del archivo final\n",
    "df_Huawei_3G = df_Huawei_3G_inicial[['RNC',\t'Cell Id',\t'MKT',\t'Cell Name',\t'RNC ID',\t'Max Transmit Power of Cell',\t'Band Indicator',\t'Cn Operator Group Index',\t'UL Frequency Ind',\t'Uplink UARFCN',\t'Downlink UARFCN',\t'Time Offset',\t'Num of Continuous in Sync Ind',\t'Num of Continuous Out of Sync Ind',\t'Radio Link Failure Timer Length',\t'DL Power Control Mode 1',\t'DL Primary Scrambling Code',\t'TX Diversity Indication',\t'Service Priority Group Identity',\t'NodeB Name',\t'Local Cell ID',\t'Location Area Code',\t'Service Area Code',\t'RAC Configuration Indication',\t'Routing Area Code',\t'STTD Support Indicator',\t'CP1 Support Indicator',\t'Closed Loop Time Adjust Mode',\t'DPCH Tx Diversity Mode for Other User',\t'FDPCH Tx Diversity Mode for Other User',\t'DPCH Tx Diversity Mode for MIMO User',\t'FDPCH Tx Diversity Mode for MIMO User',\t'Tx Diversity Mode for DC-HSDPA User',\t'Cell Oriented Cell Individual Offset',\t'Cell VP Limit Indicator',\t'DSS Cell Flag',\t'Maximum TX Power in Small DSS Coverage',\t'Common Channel Bandwidth Operator Index',\t'Hierarchy ID of Terminal Type',\t'Subrack No.',\t'Subrack name',\t'Slot No.',\t'Subsystem No.',\t'Heterogeneous Cell Flag',\t'HostType',\t'Validation indication',\t'Cell administrative state',\t'Cell MBMS state',\t'Cell MIMO state',\t'IPDL flag',\t'Cell CBS state',\t'Cell ERACH state',\t'NodeB Unique',\t'LAT',\t'LON',\t'Operation state',\t'Administrative state',\t'State explanation',\t'SSN',\t'En el gestor',\t'URA',\t'Observaciones',\t'Consolidado',\t'AT&T_Site_Name'\n",
    "]]\n",
    "\n",
    "## Archivo Final\n",
    "ruta_salida = os.path.join(ruta_destino, f'All_Huawei_3G_{fecha_ejecucion}.xlsx')\n",
    "df_Huawei_3G.to_excel(ruta_salida, index=False)#, encoding='utf-8')"
   ],
   "id": "3fdc40bc99d18f67",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7ab6149a203c8ba9"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
